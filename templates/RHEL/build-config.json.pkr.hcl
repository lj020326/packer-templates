# This file was autogenerated by the 'packer hcl2_upgrade' command. We
# recommend double checking that everything is correct before going forward. We
# also recommend treating this file as disposable. The HCL2 blocks in this
# file can be moved to other files. For example, the variable blocks could be
# moved to their own 'variables.pkr.hcl' file, etc. Those files need to be
# suffixed with '.pkr.hcl' to be visible to Packer. To use multiple files at
# once they also need to be in the same folder. 'packer inspect folder/'
# will describe to you what is in that folder.

# Avoid mixing go templating calls ( for example ```{{ upper(`string`) }}``` )
# and HCL2 calls (for example '${ var.string_value_example }' ). They won't be
# executed together and the outcome will be unknown.

# See https://www.packer.io/docs/templates/hcl_templates/blocks/packer for more info
packer {
  required_plugins {
    ansible = {
      source  = "github.com/hashicorp/ansible"
      version = "~> 1"
    }
    vsphere = {
      source  = "github.com/hashicorp/vsphere"
      version = "~> 1"
    }
  }
}

# source blocks are generated from your builders; a source can be referenced in
# build blocks. A build block runs provisioner and post-processors on a
# source. Read the documentation for source blocks here:
# https://www.packer.io/docs/templates/hcl_templates/blocks/source
source "vsphere-iso" "RHEL" {
  CPU_hot_plug           = var.vm_cpu_hot_plug
  CPUs                   = var.vm_cpu_num
  RAM                    = var.vm_mem_size
  RAM_hot_plug           = var.vm_mem_hot_plug
  RAM_reserve_all        = var.vm_mem_reserve_all
  boot_command           = local.boot_command
  boot_keygroup_interval = var.vm_boot_keygroup_interval
  boot_order             = var.vm_boot_order_install
  boot_wait              = var.vm_boot_wait
  cd_content             = var.common_data_source == "disk" ? local.data_source_content : null
  cluster                = var.vcenter_cluster
  communicator           = var.vm_communicator
  configuration_parameters = {
    "bios.bootDelay" = "5000"
    bootOrder        = var.vm_boot_order
  }
  convert_to_template  = "true"
  cpu_cores            = var.vm_cpu_cores_num
  datacenter           = var.vcenter_datacenter
  datastore            = var.vm_datastore
  disk_controller_type = [var.vm_disk_controller_type]
  firmware             = var.vm_firmware
  folder               = var.vm_build_folder
  guest_os_type        = var.vm_guest_os_type
  host                 = var.vm_host
  http_content         = var.common_data_source == "http" ? local.data_source_content : null
  insecure_connection  = "true"
  ip_settle_timeout    = var.ip_settle_timeout
  ip_wait_timeout      = var.ip_wait_timeout
  iso_checksum         = local.iso_checksum
  iso_paths            = local.iso_paths
  network_adapters {
    network      = var.vm_network_mgt
    network_card = var.vm_network_card
  }
  notes                  = local.build_notes
  password               = var.vcenter_password
  remove_cdrom           = var.vm_cdrom_remove
  shutdown_command       = local.vm_shutdown_command
  shutdown_timeout       = var.vm_shutdown_timeout
  ssh_handshake_attempts = var.ssh_handshake_attempts
  ssh_password           = local.ssh_password
  ssh_pty                = var.ssh_pty
  ssh_timeout            = var.ssh_timeout
  ssh_username           = local.ssh_username
  storage {
    disk_size             = var.vm_disk_size
    disk_thin_provisioned = var.vm_disk_thin_provisioned
  }
  username       = var.vcenter_username
  vcenter_server = var.vcenter_host
  vm_name        = var.vm_template_build_name
  vm_version     = var.common_vm_version
}

# a build block invokes sources and runs provisioning steps on them. The
# documentation for build blocks can be found here:
# https://www.packer.io/docs/templates/hcl_templates/blocks/build
build {
  sources = ["source.vsphere-iso.RHEL"]

  provisioner "shell" {
    execute_command = "echo '${var.build_username}' | {{ .Vars }} sudo -S -E bash '{{ .Path }}'"
    scripts         = ["_common/scripts/${var.vm_guest_os_family}/install_site_cacerts.sh"]
  }

  provisioner "shell" {
    environment_vars = ["BUILD_USERNAME=${var.build_username}"]
    execute_command  = "echo '${var.build_username}' | {{ .Vars }} sudo -S -E bash '{{ .Path }}'"
    scripts          = ["_common/scripts/${var.vm_guest_os_family}/base.sh", "_common/scripts/${var.vm_guest_os_family}/vmware.sh", "_common/scripts/${var.vm_guest_os_family}/sshd.sh"]
  }

  provisioner "shell" {
    environment_vars = ["BUILD_USERNAME=${var.build_username}", "BUILD_JOB_URL=${var.build_job_url}", "BUILD_JOB_ID=${var.build_job_id}", "BUILD_GIT_COMMIT_HASH=${var.build_git_commit_hash}"]
    execute_command  = "echo '${var.build_username}' | {{ .Vars }} sudo -S -E bash '{{ .Path }}'"
    script           = "_common/scripts/${var.vm_guest_os_family}/add-build-info.sh"
  }

  provisioner "shell" {
    environment_vars = ["PIP_INSTALL_VERSION=${var.pip_version}", "ANSIBLE_VAULT_PASS=${var.ansible_vault_password}"]
    execute_command  = "echo '${var.build_username}' | {{ .Vars }} bash '{{ .Path }}'"
    scripts          = ["_common/scripts/${var.vm_guest_os_family}/ansible.sh"]
  }

  provisioner "shell" {
    inline = ["mkdir -p ${var.ansible_staging_directory}"]
  }

  provisioner "file" {
    destination = "${var.ansible_staging_directory}/requirements.yml"
    source      = "${var.ansible_galaxy_req_file}"
  }

  provisioner "ansible-local" {
    clean_staging_directory = "false"
    command                 = "${var.ansible_command}"
    extra_arguments         = ["--tag", "${var.ansible_playbook_tag}", "--vault-password-file=${var.ansible_playbook_vault_password_file}", "-e", "@${var.ansible_playbook_vault}"]
    group_vars              = "${var.ansible_inventory_group_vars}"
    inventory_file          = "${var.ansible_inventory_file}"
    playbook_dir            = "${var.ansible_playbook_dir}"
    playbook_file           = "${var.ansible_playbook_file}"
    staging_directory       = "${var.ansible_staging_directory}"
  }

  provisioner "shell" {
    execute_command   = "echo '${var.build_username}' | {{ .Vars }} sudo -H -S -E bash '{{ .Path }}'"
    expect_disconnect = "true"
    script            = "_common/scripts/${var.vm_guest_os_family}/reboot.sh"
    skip_clean        = "true"
  }

  provisioner "inspec" {
    extra_arguments = ["--no-distinct-exit"]
    inspec_env_vars = ["CHEF_LICENSE=accept"]
    pause_before    = "2m0s"
    profile         = "../inspec"
    timeout         = "1h0m0s"
  }

  provisioner "shell" {
    execute_command = "echo '${var.build_username}' | {{ .Vars }} sudo -H -S -E bash '{{ .Path }}'"
    scripts         = ["_common/scripts/${var.vm_guest_os_family}/cleanup.sh", "_common/scripts/${var.vm_guest_os_family}/zerodisk.sh"]
  }

  post-processor "manifest" {
    custom_data = {
      build_date               = local.build_date
      build_username           = var.build_username
      build_version            = local.build_version
      common_data_source       = var.common_data_source
      common_vm_version        = var.common_vm_version
      vm_cpu_cores             = var.vm_cpu_cores_num
      vm_cpu_count             = var.vm_cpu_num
      vm_disk_size             = var.vm_disk_size
      vm_disk_thin_provisioned = var.vm_disk_thin_provisioned
      vm_firmware              = var.vm_firmware
      vm_guest_os_type         = var.vm_guest_os_type
      vm_mem_size              = var.vm_mem_size
      vm_network_card          = var.vm_network_card
      vsphere_cluster          = var.vcenter_cluster
      vsphere_datacenter       = var.vcenter_datacenter
      vsphere_datastore        = var.vcenter_datacenter
      vsphere_folder           = var.vm_build_folder
      vsphere_host             = var.vcenter_host
    }
    output     = "manifest.json"
    strip_path = true
  }
}
